#!/usr/bin/env python3
"""
æ–‡æœ¬ç›¸ä¼¼æ€§æœç´¢ç³»ç»Ÿç¤ºä¾‹
ä½¿ç”¨ Milvus æ„å»ºä¸€ä¸ªå®é™…çš„æ–‡æœ¬æœç´¢å¼•æ“ï¼Œæ”¯æŒè¯­ä¹‰æœç´¢åŠŸèƒ½
"""

import time
import json
import numpy as np
from typing import List, Dict, Tuple
from pymilvus import (
    connections, utility, FieldSchema, CollectionSchema, 
    DataType, Collection, MilvusException
)

class TextSearchEngine:
    """åŸºäº Milvus çš„æ–‡æœ¬ç›¸ä¼¼æ€§æœç´¢å¼•æ“"""
    
    def __init__(self, host='localhost', port='19530', collection_name='text_search'):
        self.host = host
        self.port = port
        self.collection_name = collection_name
        self.collection = None
        self.dimension = 384  # ä½¿ç”¨ sentence-transformers çš„é»˜è®¤ç»´åº¦
        
    def connect(self):
        """è¿æ¥åˆ° Milvus æœåŠ¡å™¨"""
        try:
            connections.connect("default", host=self.host, port=self.port)
            print(f"âœ… æˆåŠŸè¿æ¥åˆ° Milvus: {self.host}:{self.port}")
            return True
        except Exception as e:
            print(f"âŒ è¿æ¥å¤±è´¥: {e}")
            return False
    
    def create_collection(self):
        """åˆ›å»ºæ–‡æœ¬æœç´¢é›†åˆ"""
        # å®šä¹‰é›†åˆæ¨¡å¼
        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="title", dtype=DataType.VARCHAR, max_length=200),
            FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=2000),
            FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=50),
            FieldSchema(name="url", dtype=DataType.VARCHAR, max_length=500),
            FieldSchema(name="timestamp", dtype=DataType.INT64),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=self.dimension)
        ]
        
        schema = CollectionSchema(fields, "æ–‡æœ¬ç›¸ä¼¼æ€§æœç´¢é›†åˆ")
        
        # å¦‚æœé›†åˆå·²å­˜åœ¨ï¼Œåˆ é™¤å®ƒ
        if utility.has_collection(self.collection_name):
            print(f"ğŸ“ é›†åˆ {self.collection_name} å·²å­˜åœ¨ï¼Œæ­£åœ¨åˆ é™¤...")
            utility.drop_collection(self.collection_name)
        
        # åˆ›å»ºæ–°é›†åˆ
        self.collection = Collection(self.collection_name, schema)
        print(f"âœ… é›†åˆ {self.collection_name} åˆ›å»ºæˆåŠŸ")
        
        return self.collection
    
    def create_index(self):
        """åˆ›å»ºå‘é‡ç´¢å¼•"""
        if not self.collection:
            raise ValueError("é›†åˆå°šæœªåˆ›å»º")
        
        # ä¸ºä¸åŒè§„æ¨¡çš„æ•°æ®é€‰æ‹©åˆé€‚çš„ç´¢å¼•
        index_params = {
            "metric_type": "COSINE",  # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œé€‚åˆæ–‡æœ¬æœç´¢
            "index_type": "HNSW",     # HNSW ç´¢å¼•ï¼Œé«˜ç²¾åº¦
            "params": {
                "M": 16,
                "efConstruction": 200
            }
        }
        
        print("ğŸ”§ æ­£åœ¨åˆ›å»ºç´¢å¼•...")
        self.collection.create_index("embedding", index_params)
        print("âœ… ç´¢å¼•åˆ›å»ºå®Œæˆ")
    
    def load_collection(self):
        """åŠ è½½é›†åˆåˆ°å†…å­˜"""
        if not self.collection:
            raise ValueError("é›†åˆå°šæœªåˆ›å»º")
        
        print("ğŸ“¥ æ­£åœ¨åŠ è½½é›†åˆåˆ°å†…å­˜...")
        self.collection.load()
        print("âœ… é›†åˆåŠ è½½å®Œæˆ")
    
    def simple_text_to_vector(self, text: str) -> List[float]:
        """
        ç®€å•çš„æ–‡æœ¬å‘é‡åŒ–æ–¹æ³•ï¼ˆæ¼”ç¤ºç”¨ï¼‰
        åœ¨å®é™…åº”ç”¨ä¸­ï¼Œåº”è¯¥ä½¿ç”¨ sentence-transformers æˆ–å…¶ä»–é¢„è®­ç»ƒæ¨¡å‹
        """
        # è¿™æ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„å‘é‡åŒ–æ–¹æ³•ï¼Œä»…ç”¨äºæ¼”ç¤º
        # å®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨ sentence-transformers ç­‰åº“
        words = text.lower().split()
        vector = np.random.normal(0, 1, self.dimension).tolist()
        
        # æ·»åŠ ä¸€äº›åŸºäºæ–‡æœ¬å†…å®¹çš„ç‰¹å¾
        if words:
            # åŸºäºæ–‡æœ¬é•¿åº¦è°ƒæ•´å‘é‡
            length_factor = min(len(words) / 10.0, 1.0)
            vector = [v * length_factor for v in vector]
        
        # å½’ä¸€åŒ–å‘é‡ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦éœ€è¦ï¼‰
        norm = np.linalg.norm(vector)
        if norm > 0:
            vector = [v / norm for v in vector]
        
        return vector
    
    def insert_documents(self, documents: List[Dict]) -> bool:
        """
        æ’å…¥æ–‡æ¡£æ•°æ®
        documents æ ¼å¼: [{"title": "æ ‡é¢˜", "content": "å†…å®¹", "category": "åˆ†ç±»", "url": "é“¾æ¥"}]
        """
        if not self.collection:
            raise ValueError("é›†åˆå°šæœªåˆ›å»º")
        
        print(f"ğŸ“ æ­£åœ¨å¤„ç† {len(documents)} ä¸ªæ–‡æ¡£...")
        
        # å‡†å¤‡æ•°æ®
        titles = []
        contents = []
        categories = []
        urls = []
        timestamps = []
        embeddings = []
        
        for doc in documents:
            # ç»„åˆæ ‡é¢˜å’Œå†…å®¹ç”¨äºå‘é‡åŒ–
            full_text = f"{doc.get('title', '')} {doc.get('content', '')}"
            
            titles.append(doc.get('title', ''))
            contents.append(doc.get('content', ''))
            categories.append(doc.get('category', 'general'))
            urls.append(doc.get('url', ''))
            timestamps.append(int(time.time()))
            embeddings.append(self.simple_text_to_vector(full_text))
        
        # æ’å…¥æ•°æ®
        data = [titles, contents, categories, urls, timestamps, embeddings]
        
        try:
            insert_result = self.collection.insert(data)
            print(f"âœ… æˆåŠŸæ’å…¥ {insert_result.insert_count} æ¡æ–‡æ¡£")
            
            # å¼ºåˆ¶åˆ·æ–°åˆ°ç£ç›˜
            self.collection.flush()
            return True
            
        except Exception as e:
            print(f"âŒ æ’å…¥æ•°æ®å¤±è´¥: {e}")
            return False
    
    def search(self, query: str, top_k: int = 10, category_filter: str = None) -> List[Dict]:
        """
        æœç´¢ç›¸ä¼¼æ–‡æ¡£
        """
        if not self.collection:
            raise ValueError("é›†åˆå°šæœªåˆ›å»º")
        
        # å°†æŸ¥è¯¢è½¬æ¢ä¸ºå‘é‡
        query_vector = self.simple_text_to_vector(query)
        
        # è®¾ç½®æœç´¢å‚æ•°
        search_params = {
            "metric_type": "COSINE",
            "params": {"ef": 100}  # HNSW æœç´¢å‚æ•°
        }
        
        # æ„å»ºè¿‡æ»¤è¡¨è¾¾å¼
        expr = None
        if category_filter:
            expr = f'category == "{category_filter}"'
        
        try:
            # æ‰§è¡Œæœç´¢
            results = self.collection.search(
                [query_vector],
                "embedding",
                search_params,
                limit=top_k,
                expr=expr,
                output_fields=["title", "content", "category", "url", "timestamp"]
            )
            
            # å¤„ç†æœç´¢ç»“æœ
            search_results = []
            for hits in results:
                for hit in hits:
                    result = {
                        "id": hit.id,
                        "score": float(hit.score),  # ç›¸ä¼¼åº¦åˆ†æ•°
                        "title": hit.entity.get("title"),
                        "content": hit.entity.get("content"),
                        "category": hit.entity.get("category"),
                        "url": hit.entity.get("url"),
                        "timestamp": hit.entity.get("timestamp")
                    }
                    search_results.append(result)
            
            return search_results
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            return []
    
    def get_statistics(self) -> Dict:
        """è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯"""
        if not self.collection:
            return {}
        
        stats = {
            "collection_name": self.collection.name,
            "total_documents": self.collection.num_entities,
            "description": self.collection.description,
            "dimension": self.dimension
        }
        
        return stats
    
    def delete_documents(self, expr: str) -> bool:
        """æ ¹æ®è¡¨è¾¾å¼åˆ é™¤æ–‡æ¡£"""
        try:
            self.collection.delete(expr)
            print(f"âœ… åˆ é™¤æ“ä½œå®Œæˆ: {expr}")
            return True
        except Exception as e:
            print(f"âŒ åˆ é™¤å¤±è´¥: {e}")
            return False
    
    def disconnect(self):
        """æ–­å¼€è¿æ¥"""
        if self.collection:
            self.collection.release()
        connections.disconnect("default")
        print("ğŸ”Œ å·²æ–­å¼€è¿æ¥")

def create_sample_documents() -> List[Dict]:
    """åˆ›å»ºç¤ºä¾‹æ–‡æ¡£æ•°æ®"""
    documents = [
        {
            "title": "Python æœºå™¨å­¦ä¹ å…¥é—¨",
            "content": "Python æ˜¯ä¸€ç§å¼ºå¤§çš„ç¼–ç¨‹è¯­è¨€ï¼Œç‰¹åˆ«é€‚åˆæœºå™¨å­¦ä¹ å’Œæ•°æ®ç§‘å­¦ã€‚æœ¬æ–‡ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨ scikit-learn è¿›è¡ŒåŸºç¡€çš„æœºå™¨å­¦ä¹ ä»»åŠ¡ã€‚",
            "category": "technology",
            "url": "https://example.com/python-ml-intro"
        },
        {
            "title": "æ·±åº¦å­¦ä¹ ä¸ç¥ç»ç½‘ç»œ",
            "content": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„å¤æ‚æ¨¡å¼ã€‚TensorFlow å’Œ PyTorch æ˜¯æœ€æµè¡Œçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚",
            "category": "technology",
            "url": "https://example.com/deep-learning"
        },
        {
            "title": "å‘é‡æ•°æ®åº“çš„åº”ç”¨",
            "content": "å‘é‡æ•°æ®åº“å¦‚ Milvus ä¸“é—¨ç”¨äºå­˜å‚¨å’Œæ£€ç´¢é«˜ç»´å‘é‡æ•°æ®ï¼Œåœ¨æ¨èç³»ç»Ÿã€ç›¸ä¼¼æ€§æœç´¢å’Œ AI åº”ç”¨ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚",
            "category": "technology",
            "url": "https://example.com/vector-database"
        },
        {
            "title": "è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯",
            "content": "è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ç»“åˆäº†è®¡ç®—æœºç§‘å­¦å’Œäººå·¥æ™ºèƒ½ï¼Œå¸®åŠ©è®¡ç®—æœºç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚BERT å’Œ GPT æ˜¯é‡è¦çš„ NLP æ¨¡å‹ã€‚",
            "category": "technology",
            "url": "https://example.com/nlp-tech"
        },
        {
            "title": "å¥åº·é¥®é£ŸæŒ‡å—",
            "content": "å¥åº·çš„é¥®é£Ÿä¹ æƒ¯å¯¹èº«ä½“å¥åº·è‡³å…³é‡è¦ã€‚å»ºè®®å¤šåƒè”¬èœæ°´æœï¼Œå‡å°‘åŠ å·¥é£Ÿå“çš„æ‘„å…¥ï¼Œä¿æŒè¥å…»å‡è¡¡ã€‚",
            "category": "health",
            "url": "https://example.com/healthy-diet"
        },
        {
            "title": "è¿åŠ¨ä¸å¥èº«",
            "content": "è§„å¾‹çš„è¿åŠ¨å¯ä»¥æé«˜èº«ä½“ç´ è´¨ï¼Œå¢å¼ºå…ç–«åŠ›ã€‚æ¨èæ¯å‘¨è‡³å°‘è¿›è¡Œ 150 åˆ†é’Ÿçš„ä¸­ç­‰å¼ºåº¦æœ‰æ°§è¿åŠ¨ã€‚",
            "category": "health",
            "url": "https://example.com/exercise-fitness"
        },
        {
            "title": "æ—…è¡Œæ‘„å½±æŠ€å·§",
            "content": "æ—…è¡Œæ‘„å½±éœ€è¦æŒæ¡å…‰çº¿ã€æ„å›¾å’Œæ—¶æœºã€‚é»„é‡‘æ—¶æ®µçš„å…‰çº¿æœ€é€‚åˆæ‹æ‘„ï¼ŒåŒæ—¶è¦æ³¨æ„å‰æ™¯å’ŒèƒŒæ™¯çš„æ­é…ã€‚",
            "category": "photography",
            "url": "https://example.com/travel-photography"
        },
        {
            "title": "ç¾é£Ÿåˆ¶ä½œå¿ƒå¾—",
            "content": "çƒ¹é¥ªæ˜¯ä¸€é—¨è‰ºæœ¯ï¼Œéœ€è¦æŒæ¡ç«å€™ã€è°ƒå‘³å’Œé£Ÿææ­é…ã€‚æ–°é²œçš„é£Ÿæå’Œé€‚å½“çš„è°ƒæ–™æ˜¯åˆ¶ä½œç¾é£Ÿçš„å…³é”®ã€‚",
            "category": "cooking",
            "url": "https://example.com/cooking-tips"
        }
    ]
    
    return documents

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºæ–‡æœ¬æœç´¢å¼•æ“çš„å®Œæ•´åŠŸèƒ½"""
    print("ğŸš€ å¯åŠ¨æ–‡æœ¬ç›¸ä¼¼æ€§æœç´¢å¼•æ“æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºæœç´¢å¼•æ“å®ä¾‹
    search_engine = TextSearchEngine()
    
    try:
        # 1. è¿æ¥åˆ° Milvus
        if not search_engine.connect():
            return
        
        # 2. åˆ›å»ºé›†åˆ
        search_engine.create_collection()
        
        # 3. åˆ›å»ºç´¢å¼•
        search_engine.create_index()
        
        # 4. åŠ è½½é›†åˆ
        search_engine.load_collection()
        
        # 5. æ’å…¥ç¤ºä¾‹æ–‡æ¡£
        documents = create_sample_documents()
        search_engine.insert_documents(documents)
        
        # 6. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = search_engine.get_statistics()
        print(f"\nğŸ“Š é›†åˆç»Ÿè®¡ä¿¡æ¯:")
        print(f"   é›†åˆåç§°: {stats['collection_name']}")
        print(f"   æ–‡æ¡£æ€»æ•°: {stats['total_documents']}")
        print(f"   å‘é‡ç»´åº¦: {stats['dimension']}")
        
        # 7. æ¼”ç¤ºæœç´¢åŠŸèƒ½
        print(f"\nğŸ” æœç´¢æ¼”ç¤º:")
        print("-" * 30)
        
        queries = [
            "æœºå™¨å­¦ä¹ ç®—æ³•",
            "å¥åº·ç”Ÿæ´»æ–¹å¼",
            "æ‘„å½±æŠ€æœ¯",
            "Python ç¼–ç¨‹"
        ]
        
        for query in queries:
            print(f"\næŸ¥è¯¢: '{query}'")
            results = search_engine.search(query, top_k=3)
            
            if results:
                for i, result in enumerate(results, 1):
                    print(f"  {i}. ã€{result['category']}ã€‘{result['title']}")
                    print(f"      ç›¸ä¼¼åº¦: {result['score']:.4f}")
                    print(f"      å†…å®¹: {result['content'][:60]}...")
            else:
                print("  æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
        
        # 8. æ¼”ç¤ºåˆ†ç±»è¿‡æ»¤æœç´¢
        print(f"\nğŸ·ï¸  åˆ†ç±»è¿‡æ»¤æœç´¢æ¼”ç¤º:")
        print("-" * 30)
        
        query = "æŠ€æœ¯"
        category = "technology"
        print(f"åœ¨åˆ†ç±» '{category}' ä¸­æœç´¢: '{query}'")
        
        filtered_results = search_engine.search(query, top_k=5, category_filter=category)
        for i, result in enumerate(filtered_results, 1):
            print(f"  {i}. {result['title']} (åˆ†æ•°: {result['score']:.4f})")
        
        # 9. æ¼”ç¤ºåˆ é™¤åŠŸèƒ½
        print(f"\nğŸ—‘ï¸  åˆ é™¤æ¼”ç¤º:")
        print("-" * 30)
        
        # åˆ é™¤ç‰¹å®šåˆ†ç±»çš„æ–‡æ¡£
        delete_expr = 'category == "cooking"'
        print(f"åˆ é™¤æ¡ä»¶: {delete_expr}")
        search_engine.delete_documents(delete_expr)
        
        # æ˜¾ç¤ºæ›´æ–°åçš„ç»Ÿè®¡ä¿¡æ¯
        updated_stats = search_engine.get_statistics()
        print(f"åˆ é™¤åæ–‡æ¡£æ€»æ•°: {updated_stats['total_documents']}")
        
        print(f"\nâœ… æ¼”ç¤ºå®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        
    finally:
        # æ¸…ç†èµ„æº
        search_engine.disconnect()

if __name__ == "__main__":
    main() 