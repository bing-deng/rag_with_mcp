🔧 初始化模型管理器...
✅ 发现 transformers 库，支持 Hugging Face LLaMA 模型
✅ 支持 Ollama 本地 LLaMA 服务
🚀 启动智能查询系统 Web 服务
============================================================
Web UI: http://localhost:5001
API文档:
  GET  /api/collections - 获取所有集合
  GET  /api/collections/<name>/stats - 集合统计
  POST /api/vector-search - 向量搜索
  POST /api/llama-chat - AI问答
  GET  /health - 健康检查
------------------------------------------------------------
 * Serving Flask app 'web_app'
 * Debug mode: on
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5001
 * Running on http://10.22.111.202:5001
[33mPress CTRL+C to quit[0m
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 119-540-104
127.0.0.1 - - [30/Jul/2025 17:04:41] "GET / HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:04:41] "GET /health HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:04:42] "GET /api/collections HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:04:46] "GET /api/collections/demo_collection_fixed/stats HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:04:46] "GET /api/collections/advanced_text_search/stats HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:04:49] "GET /api/collections/kandenko_website/stats HTTP/1.1" 200 -
/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/web_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
127.0.0.1 - - [30/Jul/2025 17:05:04] "POST /api/llama-chat HTTP/1.1" 200 -
/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/web_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
127.0.0.1 - - [30/Jul/2025 17:05:35] "POST /api/llama-chat HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:06:03] "POST /api/llama-chat HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:06:27] "POST /api/llama-chat HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:07:09] "POST /api/llama-chat HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:07:54] "POST /api/llama-chat HTTP/1.1" 200 -
 * Detected change in '/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/model_manager.py', reloading
🔧 初始化模型管理器...
✅ 发现 transformers 库，支持 Hugging Face LLaMA 模型
✅ 支持 Ollama 本地 LLaMA 服务
🚀 启动智能查询系统 Web 服务
============================================================
Web UI: http://localhost:5001
API文档:
  GET  /api/collections - 获取所有集合
  GET  /api/collections/<name>/stats - 集合统计
  POST /api/vector-search - 向量搜索
  POST /api/llama-chat - AI问答
  GET  /health - 健康检查
------------------------------------------------------------
✅ 成功连接到 Milvus: localhost:19530
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 demo_collection_fixed 已加载
📊 获取统计信息...
🔌 已断开连接
✅ 集合 advanced_text_search 已加载
📊 获取统计信息...
❌ 获取统计信息失败: <ConnectionNotExistException: (code=1, message=should create connection first.)>
获取集合统计失败: <ConnectionNotExistException: (code=1, message=should create connection first.)>
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
📊 获取统计信息...
🔌 已断开连接
✅ Ollama 服务可用，可用模型: ['llama3.2:3b', 'deepseek-r1:14b']
✅ 模型 llama3.2:3b 已就绪
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
🤖 RAG 查询: '関電工の会社情報教えて'
🔍 第一步：向量搜索检索相关内容...
🔍 基础搜索: '関電工の会社情報教えて'
🔧 加载语义向量化模型 (仅此一次)...
✅ 语义模型加载完成并缓存
🌐 检测到语言: ja
🤖 第二步：LLaMA 生成智能回答...
✅ Ollama 服务可用，模型: ['llama3.2:3b', 'deepseek-r1:14b']
🔌 已断开连接
✅ Ollama 服务可用，可用模型: ['llama3.2:3b', 'deepseek-r1:14b']
✅ 模型 llama3.2:3b 已就绪
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
🤖 RAG 查询: '会社設立はいつ'
🔍 第一步：向量搜索检索相关内容...
🔍 基础搜索: '会社設立はいつ'
🌐 检测到语言: ja
🤖 第二步：LLaMA 生成智能回答...
🔌 已断开连接
✅ Ollama 服务可用，可用模型: ['llama3.2:3b', 'deepseek-r1:14b']
✅ 模型 llama3.2:3b 已就绪
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
🤖 RAG 查询: '公司电话是多少'
🔍 第一步：向量搜索检索相关内容...
🔍 基础搜索: '公司电话是多少'
🌐 检测到语言: zh
🤖 第二步：LLaMA 生成智能回答...
🔌 已断开连接
✅ Ollama 服务可用，可用模型: ['llama3.2:3b', 'deepseek-r1:14b']
✅ 模型 llama3.2:3b 已就绪
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
🤖 RAG 查询: '電話番号はなんですか'
🔍 第一步：向量搜索检索相关内容...
🔍 基础搜索: '電話番号はなんですか'
🌐 检测到语言: ja
🤖 第二步：LLaMA 生成智能回答...
🔌 已断开连接
✅ Ollama 服务可用，可用模型: ['llama3.2:3b', 'deepseek-r1:14b']
✅ 模型 llama3.2:3b 已就绪
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
🤖 RAG 查询: '株式会社　関電工の電話番号はなん'
🔍 第一步：向量搜索检索相关内容...
🔍 基础搜索: '株式会社　関電工の電話番号はなん'
🌐 检测到语言: ja
🤖 第二步：LLaMA 生成智能回答...
🔌 已断开连接
✅ Ollama 服务可用，可用模型: ['llama3.2:3b', 'deepseek-r1:14b']
✅ 模型 llama3.2:3b 已就绪
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
🤖 RAG 查询: '株式会社　関電工の採用情報を教えて'
🔍 第一步：向量搜索检索相关内容...
🔍 基础搜索: '株式会社　関電工の採用情報を教えて'
🌐 检测到语言: ja
🤖 第二步：LLaMA 生成智能回答...
🔌 已断开连接
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 119-540-104
 * Detected change in '/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/model_manager.py', reloading
🔧 初始化模型管理器...
✅ 发现 transformers 库，支持 Hugging Face LLaMA 模型
✅ 支持 Ollama 本地 LLaMA 服务
🚀 启动智能查询系统 Web 服务
============================================================
Web UI: http://localhost:5001
API文档:
  GET  /api/collections - 获取所有集合
  GET  /api/collections/<name>/stats - 集合统计
  POST /api/vector-search - 向量搜索
  POST /api/llama-chat - AI问答
  GET  /health - 健康检查
------------------------------------------------------------
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 119-540-104
 * Detected change in '/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/model_manager.py', reloading
🔧 初始化模型管理器 (带缓存)...
✅ 发现 transformers 库，支持 Hugging Face LLaMA 模型
✅ 支持 Ollama 本地 LLaMA 服务
🚀 启动智能查询系统 Web 服务
============================================================
Web UI: http://localhost:5001
API文档:
  GET  /api/collections - 获取所有集合
  GET  /api/collections/<name>/stats - 集合统计
  POST /api/vector-search - 向量搜索
  POST /api/llama-chat - AI问答
  GET  /health - 健康检查
------------------------------------------------------------
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 119-540-104
 * Detected change in '/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/web_app.py', reloading
🔧 初始化模型管理器 (带缓存)...
✅ 发现 transformers 库，支持 Hugging Face LLaMA 模型
✅ 支持 Ollama 本地 LLaMA 服务
🚀 启动智能查询系统 Web 服务
============================================================
Web UI: http://localhost:5001
API文档:
  GET  /api/collections - 获取所有集合
  GET  /api/collections/<name>/stats - 集合统计
  POST /api/vector-search - 向量搜索
  POST /api/llama-chat - AI问答
  GET  /health - 健康检查
------------------------------------------------------------
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 119-540-104
 * Detected change in '/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/web_app.py', reloading
🔧 初始化模型管理器 (带缓存)...
✅ 发现 transformers 库，支持 Hugging Face LLaMA 模型
✅ 支持 Ollama 本地 LLaMA 服务
🔧 初始化Milvus连接池...
🚀 启动智能查询系统 Web 服务
============================================================
Web UI: http://localhost:5001
API文档:
  GET  /api/collections - 获取所有集合
  GET  /api/collections/<name>/stats - 集合统计
  POST /api/vector-search - 向量搜索
  POST /api/llama-chat - AI问答
  GET  /health - 健康检查
------------------------------------------------------------
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 119-540-104
/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/web_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
127.0.0.1 - - [30/Jul/2025 17:14:37] "POST /api/llama-chat HTTP/1.1" 200 -
 * Detected change in '/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/model_manager.py', reloading
🔧 初始化模型管理器 (带缓存)...
✅ 发现 transformers 库，支持 Hugging Face LLaMA 模型
✅ 支持 Ollama 本地 LLaMA 服务
🔧 初始化Milvus连接池...
🚀 启动智能查询系统 Web 服务
============================================================
Web UI: http://localhost:5001
API文档:
  GET  /api/collections - 获取所有集合
  GET  /api/collections/<name>/stats - 集合统计
  POST /api/vector-search - 向量搜索
  POST /api/llama-chat - AI问答
  GET  /health - 健康检查
------------------------------------------------------------
📡 创建新连接: kandenko_website
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
✅ Ollama 服务可用，可用模型: ['llama3.2:3b', 'deepseek-r1:14b']
✅ 模型 llama3.2:3b 已就绪
🤖 RAG 查询: '关电工做什么业务'
🔍 第一步：向量搜索检索相关内容...
🔍 基础搜索: '关电工做什么业务'
🔧 加载语义向量化模型 (仅此一次)...
🔥 预热向量模型...
✅ 语义模型加载完成并缓存
🌐 检测到语言: zh
🤖 第二步：LLaMA 生成智能回答...
✅ Ollama 服务可用，模型: ['llama3.2:3b', 'deepseek-r1:14b']
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 119-540-104
/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/web_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
127.0.0.1 - - [30/Jul/2025 17:23:45] "POST /api/llama-chat HTTP/1.1" 200 -
 * Detected change in '/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/model_manager.py', reloading
🔧 初始化模型管理器 (带缓存)...
✅ 发现 transformers 库，支持 Hugging Face LLaMA 模型
✅ 支持 Ollama 本地 LLaMA 服务
🔧 初始化Milvus连接池...
🚀 启动智能查询系统 Web 服务
============================================================
Web UI: http://localhost:5001
API文档:
  GET  /api/collections - 获取所有集合
  GET  /api/collections/<name>/stats - 集合统计
  POST /api/vector-search - 向量搜索
  POST /api/llama-chat - AI问答
  GET  /health - 健康检查
------------------------------------------------------------
📡 创建新连接: kandenko_website
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
✅ Ollama 服务可用，可用模型: ['llama3.2:3b', 'deepseek-r1:14b']
✅ 模型 llama3.2:3b 已就绪
🤖 RAG 查询: '関電工の事業内容は？'
🔍 第一步：向量搜索检索相关内容...
🔍 基础搜索: '関電工の事業内容は？'
🔧 加载语义向量化模型 (仅此一次)...
🔥 预热向量模型...
✅ 语义模型加载完成并缓存
🌐 检测到语言: ja
🤖 第二步：LLaMA 生成智能回答...
✅ Ollama 服务可用，模型: ['llama3.2:3b', 'deepseek-r1:14b']
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 119-540-104
/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/web_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
127.0.0.1 - - [30/Jul/2025 17:24:17] "POST /api/llama-chat HTTP/1.1" 200 -
 * Detected change in '/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/model_manager.py', reloading
🔧 初始化模型管理器 (带缓存)...
✅ 发现 transformers 库，支持 Hugging Face LLaMA 模型
✅ 支持 Ollama 本地 LLaMA 服务
🔧 初始化Milvus连接池...
🚀 启动智能查询系统 Web 服务
============================================================
Web UI: http://localhost:5001
API文档:
  GET  /api/collections - 获取所有集合
  GET  /api/collections/<name>/stats - 集合统计
  POST /api/vector-search - 向量搜索
  POST /api/llama-chat - AI问答
  GET  /health - 健康检查
------------------------------------------------------------
📡 创建新连接: kandenko_website
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
✅ Ollama 服务可用，可用模型: ['llama3.2:3b', 'deepseek-r1:14b']
✅ 模型 llama3.2:3b 已就绪
🤖 RAG 查询: '株式会社　関電工の採用情報を教えて'
🔍 第一步：向量搜索检索相关内容...
🔍 基础搜索: '株式会社　関電工の採用情報を教えて'
🔧 加载语义向量化模型 (仅此一次)...
🔥 预热向量模型...
✅ 语义模型加载完成并缓存
🌐 检测到语言: ja
🤖 第二步：LLaMA 生成智能回答...
✅ Ollama 服务可用，模型: ['llama3.2:3b', 'deepseek-r1:14b']
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 119-540-104
 * Detected change in '/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/llama_query.py', reloading
🔧 初始化模型管理器 (带缓存)...
✅ 发现 transformers 库，支持 Hugging Face LLaMA 模型
✅ 支持 Ollama 本地 LLaMA 服务
🔧 初始化Milvus连接池...
🚀 启动智能查询系统 Web 服务
============================================================
Web UI: http://localhost:5001
API文档:
  GET  /api/collections - 获取所有集合
  GET  /api/collections/<name>/stats - 集合统计
  POST /api/vector-search - 向量搜索
  POST /api/llama-chat - AI问答
  GET  /health - 健康检查
------------------------------------------------------------
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 119-540-104
 * Detected change in '/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/llama_query.py', reloading
🔧 初始化模型管理器 (带缓存)...
✅ 发现 transformers 库，支持 Hugging Face LLaMA 模型
✅ 支持 Ollama 本地 LLaMA 服务
🔧 初始化Milvus连接池...
🚀 启动智能查询系统 Web 服务
============================================================
Web UI: http://localhost:5001
API文档:
  GET  /api/collections - 获取所有集合
  GET  /api/collections/<name>/stats - 集合统计
  POST /api/vector-search - 向量搜索
  POST /api/llama-chat - AI问答
  GET  /health - 健康检查
------------------------------------------------------------
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 119-540-104
 * Detected change in '/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/llama_query.py', reloading
🔧 初始化模型管理器 (带缓存)...
✅ 发现 transformers 库，支持 Hugging Face LLaMA 模型
✅ 支持 Ollama 本地 LLaMA 服务
🔧 初始化Milvus连接池...
🚀 启动智能查询系统 Web 服务
============================================================
Web UI: http://localhost:5001
API文档:
  GET  /api/collections - 获取所有集合
  GET  /api/collections/<name>/stats - 集合统计
  POST /api/vector-search - 向量搜索
  POST /api/llama-chat - AI问答
  GET  /health - 健康检查
------------------------------------------------------------
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 119-540-104
/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/web_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
127.0.0.1 - - [30/Jul/2025 17:25:42] "POST /api/llama-chat HTTP/1.1" 200 -
/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/web_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
127.0.0.1 - - [30/Jul/2025 17:25:53] "POST /api/llama-chat HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:27:50] "POST /api/llama-chat HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:29:01] "GET /health HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:29:54] "GET / HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:29:56] "GET /api/collections HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:29:58] "GET /api/collections/kandenko_website/stats HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:30:36] "POST /api/llama-chat HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:30:52] "POST /api/llama-chat HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:36:39] "POST /api/vector-search HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:36:53] "POST /api/vector-search HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:37:07] "POST /api/vector-search HTTP/1.1" 200 -
Traceback (most recent call last):
  File "/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/web_app.py", line 137, in vector_search
    results = engine.filtered_search(
        query=query,
    ...<3 lines>...
        top_k=top_k
    )
TypeError: MilvusQueryEngine.filtered_search() got an unexpected keyword argument 'url_pattern'
127.0.0.1 - - [30/Jul/2025 17:37:21] "[35m[1mPOST /api/vector-search HTTP/1.1[0m" 500 -
 * Detected change in '/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/web_app.py', reloading
🔧 初始化模型管理器 (带缓存)...
✅ 发现 transformers 库，支持 Hugging Face LLaMA 模型
✅ 支持 Ollama 本地 LLaMA 服务
🔧 初始化Milvus连接池...
🚀 启动智能查询系统 Web 服务
============================================================
Web UI: http://localhost:5001
API文档:
  GET  /api/collections - 获取所有集合
  GET  /api/collections/<name>/stats - 集合统计
  POST /api/vector-search - 向量搜索
  POST /api/llama-chat - AI问答
  GET  /health - 健康检查
------------------------------------------------------------
📡 创建新连接: kandenko_website
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
✅ Ollama 服务可用，可用模型: ['llama3.2:3b', 'deepseek-r1:14b']
✅ 模型 llama3.2:3b 已就绪
🤖 RAG 查询: '関電工の事業内容'
🔍 第一步：向量搜索检索相关内容...
🔍 基础搜索: '関電工の事業内容'
🔧 加载语义向量化模型 (仅此一次)...
🔥 预热向量模型...
✅ 语义模型加载完成并缓存
🌐 检测到语言: ja
🤖 第二步：LLaMA 生成智能回答...
✅ Ollama 服务可用，模型: ['llama3.2:3b', 'deepseek-r1:14b']
✅ Ollama 服务可用，可用模型: ['llama3.2:3b', 'deepseek-r1:14b']
✅ 模型 llama3.2:3b 已就绪
🤖 RAG 查询: '会社の電話番号'
🔍 第一步：向量搜索检索相关内容...
🔍 基础搜索: '会社の電話番号'
🌐 检测到语言: ja
🤖 第二步：LLaMA 生成智能回答...
✅ Ollama 服务可用，可用模型: ['llama3.2:3b', 'deepseek-r1:14b']
✅ 模型 llama3.2:3b 已就绪
🤖 RAG 查询: '株式会社　関電工の採用情報を教えて'
🔍 第一步：向量搜索检索相关内容...
🔍 基础搜索: '株式会社　関電工の採用情報を教えて'
🌐 检测到语言: ja
🤖 第二步：LLaMA 生成智能回答...
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
📊 获取统计信息...
🔌 已断开连接
✅ Ollama 服务可用，可用模型: ['llama3.2:3b', 'deepseek-r1:14b']
✅ 模型 llama3.2:3b 已就绪
🤖 RAG 查询: '株式会社　関電工会社概要教えて'
🔍 第一步：向量搜索检索相关内容...
🔍 基础搜索: '株式会社　関電工会社概要教えて'
❌ 搜索失败: <ConnectionNotExistException: (code=1, message=should create connection first.)>
✅ Ollama 服务可用，可用模型: ['llama3.2:3b', 'deepseek-r1:14b']
✅ 模型 llama3.2:3b 已就绪
🤖 RAG 查询: '株式会社　関電工の会社概要教えて'
🔍 第一步：向量搜索检索相关内容...
🔍 基础搜索: '株式会社　関電工の会社概要教えて'
❌ 搜索失败: <ConnectionNotExistException: (code=1, message=should create connection first.)>
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
🔍 基础搜索: '関電工'
🔌 已断开连接
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
🔍 基础搜索: '関電工'
🔌 已断开连接
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
🔍 基础搜索: '会社概要'
🔌 已断开连接
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
🔌 已断开连接
向量搜索错误: MilvusQueryEngine.filtered_search() got an unexpected keyword argument 'url_pattern'
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 119-540-104
/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/web_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
127.0.0.1 - - [30/Jul/2025 17:37:54] "POST /api/vector-search HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:38:36] "GET /api/collections/kandenko_website/stats HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:38:48] "POST /api/vector-search HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:39:00] "POST /api/vector-search HTTP/1.1" 200 -
 * Detected change in '/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/llama_query.py', reloading
🔧 初始化模型管理器 (带缓存)...
✅ 发现 transformers 库，支持 Hugging Face LLaMA 模型
✅ 支持 Ollama 本地 LLaMA 服务
🔧 初始化Milvus连接池...
🚀 启动智能查询系统 Web 服务
============================================================
Web UI: http://localhost:5001
API文档:
  GET  /api/collections - 获取所有集合
  GET  /api/collections/<name>/stats - 集合统计
  POST /api/vector-search - 向量搜索
  POST /api/llama-chat - AI问答
  GET  /health - 健康检查
------------------------------------------------------------
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
🔍 基础搜索: '関電工'
🔧 加载语义向量化模型 (仅此一次)...
🔥 预热向量模型...
✅ 语义模型加载完成并缓存
🔌 已断开连接
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
📊 获取统计信息...
🔌 已断开连接
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
🎯 高级搜索: '関電工'
   过滤条件: content_type=paragraph, url_contains=None, min_words=None
🔌 已断开连接
✅ 成功连接到 Milvus: localhost:19530
✅ 集合 kandenko_website 已加载
🎯 高级搜索: '関電工'
   过滤条件: content_type=semantic_article, url_contains=None, min_words=None
🔌 已断开连接
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 119-540-104
 * Detected change in '/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/web_app.py', reloading
🔧 初始化模型管理器 (带缓存)...
✅ 发现 transformers 库，支持 Hugging Face LLaMA 模型
✅ 支持 Ollama 本地 LLaMA 服务
🔧 初始化Milvus连接池...
🚀 启动智能查询系统 Web 服务
============================================================
Web UI: http://localhost:5001
API文档:
  GET  /api/collections - 获取所有集合
  GET  /api/collections/<name>/stats - 集合统计
  POST /api/vector-search - 向量搜索
  POST /api/llama-chat - AI问答
  GET  /health - 健康检查
------------------------------------------------------------
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 119-540-104
/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/web_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
127.0.0.1 - - [30/Jul/2025 17:39:38] "POST /api/llama-chat HTTP/1.1" 200 -
/Users/dengbingbing/Documents/startup-deng/rag_with_mcp/Milvus/web_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
127.0.0.1 - - [30/Jul/2025 17:39:57] "POST /api/llama-chat HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:41:06] "POST /api/llama-chat HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:42:07] "POST /api/llama-chat HTTP/1.1" 200 -
127.0.0.1 - - [30/Jul/2025 17:42:55] "POST /api/llama-chat HTTP/1.1" 200 -
