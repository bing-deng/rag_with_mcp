#!/usr/bin/env python3
"""
Milvus å‘é‡æ•°æ®åº“æŸ¥è¯¢ç³»ç»Ÿ
æä¾›å¤šç§æŸ¥è¯¢æ–¹å¼ï¼šåŸºç¡€å‘é‡æœç´¢ã€é«˜çº§è¿‡æ»¤ã€èšåˆæŸ¥è¯¢ç­‰
"""

import json
import time
from typing import List, Dict, Optional, Tuple
from pymilvus import connections, Collection, utility
from model_manager import get_model_manager

# è·å–å…¨å±€æ¨¡å‹ç®¡ç†å™¨
model_manager = get_model_manager()

# å°è¯•å¯¼å…¥å‘é‡åŒ–æ¨¡å‹
try:
    from sentence_transformers import SentenceTransformer
    HAS_SENTENCE_TRANSFORMERS = True
except ImportError:
    HAS_SENTENCE_TRANSFORMERS = False
    print("âš ï¸  sentence-transformers æœªå®‰è£…ï¼Œéƒ¨åˆ†åŠŸèƒ½å—é™")

class MilvusQueryEngine:
    """Milvus æŸ¥è¯¢å¼•æ“"""
    
    def __init__(self, host='localhost', port='19530', collection_name='web_content'):
        self.host = host
        self.port = port
        self.collection_name = collection_name
        self.collection = None
        self.dimension = 384
        
        # ä½¿ç”¨å…¨å±€æ¨¡å‹ç®¡ç†å™¨ï¼Œé¿å…é‡å¤åŠ è½½
        self.model = None  # ä¸å†åœ¨è¿™é‡Œåˆå§‹åŒ–æ¨¡å‹
    
    def _get_output_fields(self):
        """åŠ¨æ€è·å–è¾“å‡ºå­—æ®µåˆ—è¡¨"""
        if not self.collection:
            return ["url", "title", "content"]
            
        available_fields = [field.name for field in self.collection.schema.fields]
        output_fields = ["url", "title", "content"]
        
        # æ·»åŠ å¯é€‰å­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        optional_fields = ["content_type", "word_count", "timestamp", "category"]
        for field in optional_fields:
            if field in available_fields:
                output_fields.append(field)
        
        return output_fields
    
    def connect(self):
        """è¿æ¥åˆ° Milvus"""
        try:
            connections.connect("default", host=self.host, port=self.port)
            print(f"âœ… æˆåŠŸè¿æ¥åˆ° Milvus: {self.host}:{self.port}")
            
            # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
            if utility.has_collection(self.collection_name):
                self.collection = Collection(self.collection_name)
                self.collection.load()
                print(f"âœ… é›†åˆ {self.collection_name} å·²åŠ è½½")
                return True
            else:
                print(f"âŒ é›†åˆ {self.collection_name} ä¸å­˜åœ¨")
                print("è¯·å…ˆè¿è¡Œ html_to_milvus.py åˆ›å»ºæ•°æ®")
                return False
                
        except Exception as e:
            print(f"âŒ è¿æ¥å¤±è´¥: {e}")
            return False
    
    def text_to_vector(self, text: str) -> List[float]:
        """å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ - ä½¿ç”¨å…¨å±€æ¨¡å‹ç®¡ç†å™¨"""
        return model_manager.text_to_vector(text)
    
    def basic_search(self, query: str, top_k: int = 5) -> List[Dict]:
        """åŸºç¡€å‘é‡æœç´¢"""
        print(f"ğŸ” åŸºç¡€æœç´¢: '{query}'")
        
        query_vector = self.text_to_vector(query)
        if not query_vector:
            return []
        
        search_params = {
            "metric_type": "COSINE",
            "params": {"ef": 100}
        }
        
        try:
            results = self.collection.search(
                [query_vector],
                "embedding",
                search_params,
                limit=top_k,
                output_fields=self._get_output_fields()
            )
            
            search_results = []
            for hits in results:
                for hit in hits:
                    result = {
                        "id": hit.id,
                        "score": float(hit.score),
                        "url": hit.entity.get("url"),
                        "title": hit.entity.get("title"),
                        "content": hit.entity.get("content"),
                        "content_type": hit.entity.get("content_type", "unknown"),
                        "word_count": hit.entity.get("word_count", 0),
                        "timestamp": hit.entity.get("timestamp", 0)
                    }
                    search_results.append(result)
            
            return search_results
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            return []
    
    def filtered_search(self, query: str, content_type: str = None, 
                       url_contains: str = None, min_words: int = None, 
                       top_k: int = 5) -> List[Dict]:
        """å¸¦è¿‡æ»¤æ¡ä»¶çš„é«˜çº§æœç´¢"""
        print(f"ğŸ¯ é«˜çº§æœç´¢: '{query}'")
        print(f"   è¿‡æ»¤æ¡ä»¶: content_type={content_type}, url_contains={url_contains}, min_words={min_words}")
        
        query_vector = self.text_to_vector(query)
        if not query_vector:
            return []
        
        # æ„å»ºè¿‡æ»¤è¡¨è¾¾å¼
        filter_conditions = []
        
        if content_type:
            filter_conditions.append(f'content_type like "{content_type}%"')
        
        if url_contains:
            filter_conditions.append(f'url like "%{url_contains}%"')
        
        if min_words:
            filter_conditions.append(f'word_count >= {min_words}')
        
        expr = " and ".join(filter_conditions) if filter_conditions else None
        
        search_params = {
            "metric_type": "COSINE",
            "params": {"ef": 100}
        }
        
        try:
            results = self.collection.search(
                [query_vector],
                "embedding",
                search_params,
                limit=top_k,
                expr=expr,
                output_fields=self._get_output_fields()
            )
            
            search_results = []
            for hits in results:
                for hit in hits:
                    search_results.append({
                        "id": hit.id,
                        "score": float(hit.score),
                        "url": hit.entity.get("url"),
                        "title": hit.entity.get("title"),
                        "content": hit.entity.get("content"),
                        "content_type": hit.entity.get("content_type"),
                        "word_count": hit.entity.get("word_count"),
                        "timestamp": hit.entity.get("timestamp")
                    })
            
            return search_results
            
        except Exception as e:
            print(f"âŒ é«˜çº§æœç´¢å¤±è´¥: {e}")
            return []
    
    def get_by_ids(self, ids: List[int]) -> List[Dict]:
        """æ ¹æ®IDè·å–å…·ä½“è®°å½•"""
        print(f"ğŸ“‹ æ ¹æ®IDè·å–è®°å½•: {ids}")
        
        try:
            # æ„å»ºIDè¿‡æ»¤è¡¨è¾¾å¼
            id_list = ", ".join(map(str, ids))
            expr = f"id in [{id_list}]"
            
            results = self.collection.query(
                expr=expr,
                output_fields=self._get_output_fields()
            )
            
            return results
            
        except Exception as e:
            print(f"âŒ IDæŸ¥è¯¢å¤±è´¥: {e}")
            return []
    
    def get_statistics(self) -> Dict:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        print("ğŸ“Š è·å–ç»Ÿè®¡ä¿¡æ¯...")
        
        try:
            stats = {
                "collection_name": self.collection.name,
                "total_records": self.collection.num_entities,
                "dimension": self.dimension
            }
            
            # é¦–å…ˆæ£€æŸ¥é›†åˆschemaï¼Œç¡®å®šå¯ç”¨å­—æ®µ
            schema = self.collection.schema
            available_fields = [field.name for field in schema.fields]
            
            # åªæŸ¥è¯¢å­˜åœ¨çš„å­—æ®µ
            query_fields = []
            if "content_type" in available_fields:
                query_fields.append("content_type")
            if "url" in available_fields:
                query_fields.append("url")
            if "title" in available_fields:
                query_fields.append("title")
            
            if not query_fields:
                # å¦‚æœæ²¡æœ‰è¿™äº›å­—æ®µï¼Œåªè¿”å›åŸºç¡€ç»Ÿè®¡
                return stats
            
            # è·å–å†…å®¹ç±»å‹åˆ†å¸ƒï¼ˆå¦‚æœå­—æ®µå­˜åœ¨ï¼‰
            if "content_type" in query_fields:
                try:
                    content_types = self.collection.query(
                        expr="id >= 0",
                        output_fields=["content_type"],
                        limit=10000
                    )
                    
                    type_counts = {}
                    for item in content_types:
                        ct = item.get('content_type', 'unknown')
                        type_counts[ct] = type_counts.get(ct, 0) + 1
                    
                    stats["content_type_distribution"] = type_counts
                except Exception as e:
                    print(f"è·å–content_typeç»Ÿè®¡å¤±è´¥: {e}")
            
            # è·å–URLåˆ†å¸ƒï¼ˆå¦‚æœå­—æ®µå­˜åœ¨ï¼‰
            if "url" in query_fields:
                try:
                    urls = self.collection.query(
                        expr="id >= 0",
                        output_fields=["url"],
                        limit=10000
                    )
                    
                    url_counts = {}
                    for item in urls:
                        url = item.get('url', 'unknown')
                        # ç®€åŒ–URLæ˜¾ç¤º
                        if len(url) > 50:
                            url = url[:50] + "..."
                        url_counts[url] = url_counts.get(url, 0) + 1
                    
                    stats["url_distribution"] = url_counts
                except Exception as e:
                    print(f"è·å–urlç»Ÿè®¡å¤±è´¥: {e}")
            
            return stats
            
        except Exception as e:
            print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def content_type_search(self, content_type: str, limit: int = 10) -> List[Dict]:
        """æŒ‰å†…å®¹ç±»å‹æµè§ˆ"""
        print(f"ğŸ“ æµè§ˆå†…å®¹ç±»å‹: {content_type}")
        
        try:
            expr = f'content_type == "{content_type}"'
            
            results = self.collection.query(
                expr=expr,
                output_fields=["url", "title", "content", "word_count"],
                limit=limit
            )
            
            return results
            
        except Exception as e:
            print(f"âŒ å†…å®¹ç±»å‹æŸ¥è¯¢å¤±è´¥: {e}")
            return []
    
    def recent_content(self, days: int = 7, limit: int = 10) -> List[Dict]:
        """è·å–æœ€è¿‘æ·»åŠ çš„å†…å®¹"""
        print(f"ğŸ“… è·å–æœ€è¿‘ {days} å¤©çš„å†…å®¹")
        
        try:
            cutoff_time = int(time.time()) - (days * 24 * 3600)
            expr = f"timestamp >= {cutoff_time}"
            
            results = self.collection.query(
                expr=expr,
                output_fields=["url", "title", "content", "content_type", "timestamp"],
                limit=limit
            )
            
            # æŒ‰æ—¶é—´æ’åº
            results.sort(key=lambda x: x.get('timestamp', 0), reverse=True)
            
            return results
            
        except Exception as e:
            print(f"âŒ è·å–æœ€è¿‘å†…å®¹å¤±è´¥: {e}")
            return []
    
    def similarity_between_contents(self, id1: int, id2: int) -> float:
        """è®¡ç®—ä¸¤ä¸ªå†…å®¹ä¹‹é—´çš„ç›¸ä¼¼åº¦"""
        print(f"ğŸ”— è®¡ç®—å†…å®¹ç›¸ä¼¼åº¦: ID {id1} vs ID {id2}")
        
        try:
            # è·å–ä¸¤ä¸ªå†…å®¹çš„å‘é‡
            results = self.collection.query(
                expr=f"id in [{id1}, {id2}]",
                output_fields=["embedding", "content"]
            )
            
            if len(results) != 2:
                print("âŒ æ— æ³•æ‰¾åˆ°æŒ‡å®šçš„å†…å®¹")
                return 0.0
            
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            import numpy as np
            
            vec1 = np.array(results[0]['embedding'])
            vec2 = np.array(results[1]['embedding'])
            
            similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
            
            print(f"ç›¸ä¼¼åº¦: {similarity:.4f}")
            print(f"å†…å®¹1: {results[0]['content'][:100]}...")
            print(f"å†…å®¹2: {results[1]['content'][:100]}...")
            
            return float(similarity)
            
        except Exception as e:
            print(f"âŒ ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def disconnect(self):
        """æ–­å¼€è¿æ¥"""
        if self.collection:
            self.collection.release()
        connections.disconnect("default")
        print("ğŸ”Œ å·²æ–­å¼€è¿æ¥")

def print_search_results(results: List[Dict], title: str = "æœç´¢ç»“æœ"):
    """æ ¼å¼åŒ–æ‰“å°æœç´¢ç»“æœ"""
    print(f"\nğŸ“‹ {title} (å…± {len(results)} æ¡):")
    print("=" * 80)
    
    for i, result in enumerate(results, 1):
        print(f"{i}. ã€{result.get('content_type', 'unknown')}ã€‘")
        print(f"   ç›¸ä¼¼åº¦: {result.get('score', 0):.4f}")
        print(f"   æ ‡é¢˜: {result.get('title', 'N/A')}")
        print(f"   æ¥æº: {result.get('url', 'N/A')}")
        print(f"   å­—æ•°: {result.get('word_count', 0)}")
        
        content = result.get('content', '')
        if len(content) > 150:
            content = content[:150] + "..."
        print(f"   å†…å®¹: {content}")
        print("-" * 80)

def interactive_query_demo():
    """äº¤äº’å¼æŸ¥è¯¢æ¼”ç¤º"""
    engine = MilvusQueryEngine()
    
    if not engine.connect():
        return
    
    try:
        while True:
            print("\nğŸ” Milvus æŸ¥è¯¢ç³»ç»Ÿ")
            print("=" * 40)
            print("1. åŸºç¡€è¯­ä¹‰æœç´¢")
            print("2. é«˜çº§è¿‡æ»¤æœç´¢") 
            print("3. æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯")
            print("4. æŒ‰å†…å®¹ç±»å‹æµè§ˆ")
            print("5. æŸ¥çœ‹æœ€è¿‘å†…å®¹")
            print("6. IDç²¾ç¡®æŸ¥è¯¢")
            print("7. å†…å®¹ç›¸ä¼¼åº¦æ¯”è¾ƒ")
            print("0. é€€å‡º")
            
            choice = input("\nè¯·é€‰æ‹©åŠŸèƒ½ (0-7): ").strip()
            
            if choice == "0":
                break
            elif choice == "1":
                query = input("è¯·è¾“å…¥æœç´¢æŸ¥è¯¢: ").strip()
                if query:
                    results = engine.basic_search(query, top_k=5)
                    print_search_results(results, "åŸºç¡€æœç´¢ç»“æœ")
            
            elif choice == "2":
                query = input("è¯·è¾“å…¥æœç´¢æŸ¥è¯¢: ").strip()
                content_type = input("å†…å®¹ç±»å‹è¿‡æ»¤ (å¯é€‰, å¦‚: paragraph, heading): ").strip() or None
                url_contains = input("URLåŒ…å« (å¯é€‰): ").strip() or None
                min_words_str = input("æœ€å°å­—æ•° (å¯é€‰): ").strip()
                min_words = int(min_words_str) if min_words_str.isdigit() else None
                
                if query:
                    results = engine.filtered_search(
                        query, content_type, url_contains, min_words, top_k=5
                    )
                    print_search_results(results, "é«˜çº§æœç´¢ç»“æœ")
            
            elif choice == "3":
                stats = engine.get_statistics()
                print(f"\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡:")
                print(f"é›†åˆåç§°: {stats.get('collection_name', 'N/A')}")
                print(f"æ€»è®°å½•æ•°: {stats.get('total_records', 'N/A')}")
                print(f"å‘é‡ç»´åº¦: {stats.get('dimension', 'N/A')}")
                
                if 'content_type_distribution' in stats:
                    print("\nå†…å®¹ç±»å‹åˆ†å¸ƒ:")
                    for ct, count in stats['content_type_distribution'].items():
                        print(f"  {ct}: {count}")
                
                if 'url_distribution' in stats:
                    print("\nURLåˆ†å¸ƒ (å‰10ä¸ª):")
                    sorted_urls = sorted(stats['url_distribution'].items(), 
                                       key=lambda x: x[1], reverse=True)
                    for url, count in sorted_urls[:10]:
                        print(f"  {url}: {count}")
            
            elif choice == "4":
                content_type = input("è¯·è¾“å…¥å†…å®¹ç±»å‹ (å¦‚: paragraph, heading_h1, list): ").strip()
                if content_type:
                    results = engine.content_type_search(content_type, limit=5)
                    print_search_results(results, f"å†…å®¹ç±»å‹: {content_type}")
            
            elif choice == "5":
                days_str = input("æŸ¥çœ‹æœ€è¿‘å‡ å¤©çš„å†…å®¹ (é»˜è®¤7å¤©): ").strip()
                days = int(days_str) if days_str.isdigit() else 7
                results = engine.recent_content(days, limit=5)
                print_search_results(results, f"æœ€è¿‘ {days} å¤©çš„å†…å®¹")
            
            elif choice == "6":
                ids_str = input("è¯·è¾“å…¥IDåˆ—è¡¨ (ç”¨é€—å·åˆ†éš”, å¦‚: 1,2,3): ").strip()
                try:
                    ids = [int(x.strip()) for x in ids_str.split(',')]
                    results = engine.get_by_ids(ids)
                    print_search_results(results, f"IDæŸ¥è¯¢ç»“æœ")
                except ValueError:
                    print("âŒ IDæ ¼å¼é”™è¯¯")
            
            elif choice == "7":
                try:
                    id1 = int(input("è¯·è¾“å…¥ç¬¬ä¸€ä¸ªå†…å®¹ID: ").strip())
                    id2 = int(input("è¯·è¾“å…¥ç¬¬äºŒä¸ªå†…å®¹ID: ").strip())
                    similarity = engine.similarity_between_contents(id1, id2)
                except ValueError:
                    print("âŒ IDå¿…é¡»æ˜¯æ•°å­—")
            
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©")
    
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­")
    
    finally:
        engine.disconnect()

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸ” Milvus Python æŸ¥è¯¢æ¼”ç¤º")
    print("=" * 50)
    
    engine = MilvusQueryEngine()
    
    if not engine.connect():
        return
    
    try:
        # 1. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = engine.get_statistics()
        print(f"\nğŸ“Š æ•°æ®åº“æ¦‚å†µ:")
        print(f"   æ€»è®°å½•æ•°: {stats.get('total_records', 'N/A')}")
        if 'content_type_distribution' in stats:
            print("   å†…å®¹ç±»å‹åˆ†å¸ƒ:")
            for ct, count in list(stats['content_type_distribution'].items())[:5]:
                print(f"     {ct}: {count}")
        
        # 2. åŸºç¡€æœç´¢æ¼”ç¤º
        test_queries = [
            "é‡‘èç›‘ç®¡æ”¿ç­–",
            "ä¼ä¸šè´¢åŠ¡æŠ¥å‘Š",
            "æŠ•èµ„é£é™©ç®¡ç†",
            "å¸‚åœºç›‘ç£åˆ¶åº¦"
        ]
        
        for query in test_queries:
            print(f"\nğŸ” æœç´¢æ¼”ç¤º: '{query}'")
            results = engine.basic_search(query, top_k=3)
            if results:
                for i, result in enumerate(results, 1):
                    print(f"  {i}. ã€{result['content_type']}ã€‘ç›¸ä¼¼åº¦: {result['score']:.4f}")
                    print(f"      {result['content'][:100]}...")
            else:
                print("  æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
        
        # 3. é«˜çº§æœç´¢æ¼”ç¤º
        print(f"\nğŸ¯ é«˜çº§æœç´¢æ¼”ç¤º:")
        advanced_results = engine.filtered_search(
            "æ³•è§„åˆ¶åº¦", 
            content_type="paragraph", 
            min_words=20, 
            top_k=3
        )
        for i, result in enumerate(advanced_results, 1):
            print(f"  {i}. {result['content'][:80]}... (åˆ†æ•°: {result['score']:.4f})")
        
        print(f"\nâœ… Python æŸ¥è¯¢æ¼”ç¤ºå®Œæˆ!")
        print("ğŸ’¡ è¿è¡Œ interactive_query_demo() è¿›å…¥äº¤äº’å¼æŸ¥è¯¢æ¨¡å¼")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        
    finally:
        engine.disconnect()

if __name__ == "__main__":
    # è¿è¡Œä¸»æ¼”ç¤º
    # main()
    
    # å¦‚æœéœ€è¦äº¤äº’å¼æŸ¥è¯¢ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Š
    # print("\n" + "="*60)
    interactive_query_demo() 