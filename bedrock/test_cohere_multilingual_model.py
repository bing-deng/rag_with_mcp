#!/usr/bin/env python3
"""
Cohere Embed Multilingual è¯¦ç»†åŠŸèƒ½æµ‹è¯•
éªŒè¯å¤šè¯­è¨€åµŒå…¥å‘é‡çš„å„ç§ä½¿ç”¨åœºæ™¯
"""

import boto3
import json
import numpy as np
from botocore.exceptions import ClientError

def detailed_cohere_test():
    """è¯¦ç»†æµ‹è¯•Cohereå¤šè¯­è¨€æ¨¡å‹"""
    
    print("=== Cohere Embed Multilingual è¯¦ç»†æµ‹è¯• ===")
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    region_name = 'ap-northeast-1'
    bedrock_runtime = boto3.client('bedrock-runtime', region_name=region_name)
    model_id = 'cohere.embed-multilingual-v3'
    
    print(f"ä½¿ç”¨æ¨¡å‹: {model_id}")
    print(f"åŒºåŸŸ: {region_name}")
    print("-" * 50)
    
    # æµ‹è¯•1: å•ä¸ªæ–‡æœ¬åµŒå…¥
    print("\n1. å•ä¸ªæ–‡æœ¬åµŒå…¥æµ‹è¯•...")
    
    single_text = "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ"
    
    try:
        body = {
            "texts": [single_text],
            "input_type": "search_document",
            "embedding_types": ["float"],
            "truncate": "END"
        }
        
        response = bedrock_runtime.invoke_model(
            modelId=model_id,
            contentType='application/json',
            accept='*/*',
            body=json.dumps(body)
        )
        
        result = json.loads(response['body'].read())
        embeddings = result['embeddings']
        
        print(f"âœ… å•ä¸ªæ–‡æœ¬åµŒå…¥æˆåŠŸ")
        print(f"   ğŸ“ æ–‡æœ¬: {single_text}")
        print(f"   ğŸ“Š å‘é‡æ•°é‡: {len(embeddings)}")
        print(f"   ğŸ“ å‘é‡ç»´åº¦: {len(embeddings[0])}")
        print(f"   ğŸ“ˆ å‘é‡å‰5ä½: {embeddings[0][:5]}")
        
    except Exception as e:
        print(f"âŒ å•ä¸ªæ–‡æœ¬åµŒå…¥å¤±è´¥: {e}")
    
    # æµ‹è¯•2: å¤šä¸ªæ–‡æœ¬åµŒå…¥ï¼ˆé€æ­¥å¢åŠ ï¼‰
    print("\n2. å¤šæ–‡æœ¬åµŒå…¥æµ‹è¯•...")
    
    test_cases = [
        ["Hello world"],
        ["Hello world", "ä½ å¥½ä¸–ç•Œ"],
        ["Hello world", "ä½ å¥½ä¸–ç•Œ", "ã“ã‚“ã«ã¡ã¯ä¸–ç•Œ"],
        ["Hello world", "ä½ å¥½ä¸–ç•Œ", "ã“ã‚“ã«ã¡ã¯ä¸–ç•Œ", "Bonjour le monde"],
        ["Hello world", "ä½ å¥½ä¸–ç•Œ", "ã“ã‚“ã«ã¡ã¯ä¸–ç•Œ", "Bonjour le monde", "Hola mundo"]
    ]
    
    for i, texts in enumerate(test_cases, 1):
        try:
            body = {
                "texts": texts,
                "input_type": "search_document",
                "embedding_types": ["float"],
                "truncate": "END"
            }
            
            response = bedrock_runtime.invoke_model(
                modelId=model_id,
                contentType='application/json',
                accept='*/*',
                body=json.dumps(body)
            )
            
            result = json.loads(response['body'].read())
            embeddings = result['embeddings']
            
            print(f"   æµ‹è¯•{i}: {len(texts)}ä¸ªæ–‡æœ¬")
            print(f"   âœ… æˆåŠŸç”Ÿæˆ {len(embeddings)} ä¸ªåµŒå…¥å‘é‡")
            
            if len(embeddings) != len(texts):
                print(f"   âš ï¸  å‘é‡æ•°é‡ä¸åŒ¹é…ï¼æœŸæœ›{len(texts)}ä¸ªï¼Œå®é™…{len(embeddings)}ä¸ª")
            
        except Exception as e:
            print(f"   âŒ æµ‹è¯•{i}å¤±è´¥: {e}")
    
    # æµ‹è¯•3: ä¸åŒinput_typeçš„å½±å“
    print("\n3. ä¸åŒinput_typeæµ‹è¯•...")
    
    test_text = "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯"
    input_types = ["search_document", "search_query", "classification", "clustering"]
    
    embeddings_by_type = {}
    
    for input_type in input_types:
        try:
            body = {
                "texts": [test_text],
                "input_type": input_type,
                "embedding_types": ["float"],
                "truncate": "END"
            }
            
            response = bedrock_runtime.invoke_model(
                modelId=model_id,
                contentType='application/json',
                accept='*/*',
                body=json.dumps(body)
            )
            
            result = json.loads(response['body'].read())
            embeddings = result['embeddings']
            
            embeddings_by_type[input_type] = embeddings[0]
            print(f"   âœ… {input_type}: æˆåŠŸ")
            
        except Exception as e:
            print(f"   âŒ {input_type}: å¤±è´¥ - {e}")
    
    # æ¯”è¾ƒä¸åŒinput_typeçš„ç›¸ä¼¼åº¦
    if len(embeddings_by_type) >= 2:
        print("\n   ğŸ“Š ä¸åŒinput_typeçš„å‘é‡ç›¸ä¼¼åº¦:")
        types = list(embeddings_by_type.keys())
        for i in range(len(types)):
            for j in range(i+1, len(types)):
                vec1 = np.array(embeddings_by_type[types[i]])
                vec2 = np.array(embeddings_by_type[types[j]])
                similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
                print(f"      {types[i]} â†” {types[j]}: {similarity:.4f}")
    
    # æµ‹è¯•4: å¤šè¯­è¨€è¯­ä¹‰æœç´¢
    print("\n4. å¤šè¯­è¨€è¯­ä¹‰æœç´¢æµ‹è¯•...")
    
    # æŸ¥è¯¢ï¼ˆè‹±æ–‡ï¼‰
    query = "What is artificial intelligence?"
    
    # å¤šè¯­è¨€æ–‡æ¡£åº“
    documents = [
        "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿ",  # ä¸­æ–‡
        "Artificial intelligence is a branch of computer science that aims to create intelligent machines",  # è‹±æ–‡
        "äººå·¥çŸ¥èƒ½ã¯ã€äººé–“ã®çŸ¥èƒ½ã‚’å¿…è¦ã¨ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã§ãã‚‹ã‚·ã‚¹ãƒ†ãƒ ã®ä½œæˆã‚’ç›®æŒ‡ã™ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®åˆ†é‡ã§ã™",  # æ—¥æ–‡
        "L'intelligence artificielle est une branche de l'informatique qui vise Ã  crÃ©er des machines intelligentes",  # æ³•æ–‡
        "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºå»æ•£æ­¥",  # ä¸ç›¸å…³çš„ä¸­æ–‡
        "I like to eat pizza on weekends"  # ä¸ç›¸å…³çš„è‹±æ–‡
    ]
    
    try:
        # è·å–æŸ¥è¯¢åµŒå…¥å‘é‡
        query_body = {
            "texts": [query],
            "input_type": "search_query",
            "embedding_types": ["float"],
            "truncate": "END"
        }
        
        query_response = bedrock_runtime.invoke_model(
            modelId=model_id,
            contentType='application/json',
            accept='*/*',
            body=json.dumps(query_body)
        )
        
        query_result = json.loads(query_response['body'].read())
        query_embedding = query_result['embeddings'][0]
        
        # è·å–æ–‡æ¡£åµŒå…¥å‘é‡
        doc_body = {
            "texts": documents,
            "input_type": "search_document", 
            "embedding_types": ["float"],
            "truncate": "END"
        }
        
        doc_response = bedrock_runtime.invoke_model(
            modelId=model_id,
            contentType='application/json',
            accept='*/*',
            body=json.dumps(doc_body)
        )
        
        doc_result = json.loads(doc_response['body'].read())
        doc_embeddings = doc_result['embeddings']
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        query_vec = np.array(query_embedding)
        similarities = []
        
        for i, doc_embedding in enumerate(doc_embeddings):
            doc_vec = np.array(doc_embedding)
            similarity = np.dot(query_vec, doc_vec) / (
                np.linalg.norm(query_vec) * np.linalg.norm(doc_vec)
            )
            similarities.append({
                'index': i,
                'document': documents[i],
                'similarity': float(similarity)
            })
        
        # æ’åº
        similarities.sort(key=lambda x: x['similarity'], reverse=True)
        
        print(f"   âœ… å¤šè¯­è¨€æœç´¢æˆåŠŸ!")
        print(f"   ğŸ” æŸ¥è¯¢: {query}")
        print(f"   ğŸ“Š ç”ŸæˆæŸ¥è¯¢å‘é‡: 1ä¸ª")
        print(f"   ğŸ“Š ç”Ÿæˆæ–‡æ¡£å‘é‡: {len(doc_embeddings)}ä¸ª")
        print("   ğŸ“‹ æœç´¢ç»“æœï¼ˆæŒ‰ç›¸ä¼¼åº¦æ’åºï¼‰:")
        
        for i, result in enumerate(similarities, 1):
            doc_preview = result['document'][:50] + "..." if len(result['document']) > 50 else result['document']
            print(f"      {i}. ç›¸ä¼¼åº¦: {result['similarity']:.4f}")
            print(f"         æ–‡æ¡£: {doc_preview}")
        
    except Exception as e:
        print(f"   âŒ å¤šè¯­è¨€æœç´¢å¤±è´¥: {e}")
    
    # æµ‹è¯•5: æ‰¹é‡å¤„ç†é™åˆ¶æµ‹è¯•
    print("\n5. æ‰¹é‡å¤„ç†é™åˆ¶æµ‹è¯•...")
    
    batch_sizes = [1, 5, 10, 20, 50]
    
    for batch_size in batch_sizes:
        texts = [f"è¿™æ˜¯æµ‹è¯•æ–‡æœ¬ç¬¬{i+1}æ¡" for i in range(batch_size)]
        
        try:
            body = {
                "texts": texts,
                "input_type": "search_document",
                "embedding_types": ["float"],
                "truncate": "END"
            }
            
            response = bedrock_runtime.invoke_model(
                modelId=model_id,
                contentType='application/json',
                accept='*/*',
                body=json.dumps(body)
            )
            
            result = json.loads(response['body'].read())
            embeddings = result['embeddings']
            
            print(f"   æ‰¹é‡å¤§å° {batch_size}: âœ… æˆåŠŸç”Ÿæˆ {len(embeddings)} ä¸ªå‘é‡")
            
        except Exception as e:
            print(f"   æ‰¹é‡å¤§å° {batch_size}: âŒ å¤±è´¥ - {e}")
    
    print(f"\n{'='*60}")
    print("ğŸ‰ Cohere Embed Multilingual æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("1. âœ… å¤šè¯­è¨€åµŒå…¥åŠŸèƒ½æ­£å¸¸")
    print("2. âœ… æ”¯æŒæ‰¹é‡å¤„ç†")
    print("3. âœ… ä¸åŒinput_typeäº§ç”Ÿä¸åŒçš„å‘é‡è¡¨ç¤º")
    print("4. âœ… è·¨è¯­è¨€è¯­ä¹‰æœç´¢æ•ˆæœè‰¯å¥½")
    print("5. ğŸ“Š å‘é‡ç»´åº¦: 1024")
    print("6. ğŸŒ å»ºè®®ç”¨äºå¤šè¯­è¨€åº”ç”¨åœºæ™¯")

if __name__ == "__main__":
    detailed_cohere_test()